---
title: "Research"
format: html
toc: true
toc-title: On this page
number-sections: false
anchor-sections: true
page-layout: full
---

## 🚀 Research Vision {#research-vision}

I aim to advance the frontier of **safe, interpretable, and adaptive AI** for cyber-physical systems operating under uncertainty and dynamic constraints. My research sits at the intersection of **machine learning**, **optimization**, and **control theory**, with a particular focus on:

- ⚙️ **Physics-informed Deep Reinforcement Learning (DRL)**
- 🔍 **Probabilistic & Bayesian Modeling**
- 🧠 **Large Language Models (LLMs) for autonomous reasoning**
- 🖼️ **Vision-based simulation environments**

By tightly integrating domain knowledge into learning frameworks, I design agents capable of robust decision-making in real-world, high-stakes environments such as **smart grids**, **robotics**, and **intelligent infrastructure**.

---

## 🌟 Research Highlights {#research-highlights}

- ✅ Proposed the first Physics-Informed LSTM-PPO agent for volt-var control on 8500-node networks.
- 📉 Achieved 98% reduction in voltage violations and 3× faster convergence in federated DRL.
- 🧠 Developed one-shot transfer learning for control agents in complex topologies.
- 🤖 Integrated LLM-guided planning into multi-building simulations via CityLearn.
- 🔒 Built resilient DRL systems that withstand adversarial and distributional attacks.

---

## 🧠 Research Focus Areas {#research-focus}

::: {.panel-tabset}

### 🔐 Safe & Trustworthy Reinforcement Learning {#safe-rl}

<div style="display: flex; flex-wrap: wrap; align-items: center; gap: 1rem; padding: 1rem; border: 1.5px solid #ddd; border-radius: 12px; background-color: #f9fbfd; box-shadow: 1px 1px 6px rgba(0,0,0,0.05); margin-bottom: 1.5rem;">
<div style="flex: 1 1 300px; min-width: 250px;">
<p><strong>🎯 Objective</strong></p>
<p>Develop control agents that guarantee <strong>system safety</strong>, <strong>stability</strong>, and <strong>robust learning</strong> in dynamic, uncertain, and partially observable environments.</p>

<p><strong>🔍 Core Focus Areas</strong></p>
<ul>
<li>🧩 Constrained policy optimization and reward shaping</li>
<li>🔬 Physics-based priors in DRL</li>
<li>🛡️ Adversarial resilience and anomaly detection</li>
<li>📏 Epistemic and aleatoric uncertainty quantification</li>
</ul>
</div>
<div style="flex: 1 1 250px; text-align: center;">
<img src="/projects1/ehr/hex_ggehr.png" alt="Safe RL Diagram" style="max-width: 100%; border-radius: 8px;">
</div>
</div>

---

### 🔄 Transfer Learning & Meta-Adaptation {#tl-rl}

<div style="display: flex; flex-wrap: wrap; align-items: center; gap: 1rem; padding: 1rem; border: 1.5px solid #ddd; border-radius: 12px; background-color: #f9fbfd; box-shadow: 1px 1px 6px rgba(0,0,0,0.05); margin-bottom: 1.5rem;">
<div style="flex: 1 1 300px; min-width: 250px;">
<p><strong>🎯 Objective</strong></p>
<p>Enable rapid generalization across distribution shifts in topology, weather, or load profiles.</p>

<p><strong>🔍 Core Focus Areas</strong></p>
<ul>
<li>⚙️ Transferable actor-critic architectures</li>
<li>🛰️ Simulation-to-real (Sim2Real) adaptation</li>
<li>🧠 Meta-RL for sample efficiency</li>
</ul>
</div>
<div style="flex: 1 1 250px; text-align: center;">
<img src="/projects1/ehr/hex_ggehr.png" alt="Transfer Learning Diagram" style="max-width: 100%; border-radius: 8px;">
</div>
</div>

---

### 👁️ Vision-Simulation Integration {#vision-sim}

<div style="display: flex; flex-wrap: wrap; align-items: center; gap: 1rem; padding: 1rem; border: 1.5px solid #ddd; border-radius: 12px; background-color: #f9fbfd; box-shadow: 1px 1px 6px rgba(0,0,0,0.05); margin-bottom: 1.5rem;">
<div style="flex: 1 1 300px; min-width: 250px;">
<p><strong>🎯 Objective</strong></p>
<p>Bridge the gap between perception and control by combining <strong>synthetic sensors</strong>, <strong>simulated environments</strong>, and <strong>end-to-end learning pipelines</strong>.</p>

<p><strong>🔍 Core Focus Areas</strong></p>
<ul>
<li>🚗 Perception-action loops with CARLA, AirSim</li>
<li>🔀 Multi-modal representation fusion (image + state)</li>
<li>🎯 Autonomous control with embedded perception</li>
<li>🔁 End-to-end control pipelines</li>
</ul>
</div>
<div style="flex: 1 1 250px; text-align: center;">
<img src="/projects1/ehr/hex_ggehr.png" alt="Vision Simulation Diagram" style="max-width: 100%; border-radius: 8px;">
</div>
</div>

---

### 🧠 LLM-Augmented Decision Systems {#llm-control}

<div style="display: flex; flex-wrap: wrap; align-items: center; gap: 1rem; padding: 1rem; border: 1.5px solid #ddd; border-radius: 12px; background-color: #f9fbfd; box-shadow: 1px 1px 6px rgba(0,0,0,0.05); margin-bottom: 1.5rem;">
<div style="flex: 1 1 300px; min-width: 250px;">
<p><strong>🎯 Objective</strong></p>
<p>Empower agents to interpret language-based inputs and coordinate intelligently in multi-agent and human-AI settings.</p>

<p><strong>🔍 Core Focus Areas</strong></p>
<ul>
<li>🧾 LLMs for summarizing states and guiding actions</li>
<li>🗣️ Translating natural language into policy primitives</li>
<li>👥 Facilitating human-AI collaboration</li>
</ul>
</div>
<div style="flex: 1 1 250px; text-align: center;">
<img src="/projects1/ehr/hex_ggehr.png" alt="LLM Control Diagram" style="max-width: 100%; border-radius: 8px;">
</div>
</div>

:::

---

## 🧠 Research Focus Areas {#research-focus}

<div class="proj-grid" style="display:grid; grid-template-columns:repeat(auto-fill,minmax(280px,1fr)); gap:1.5rem; margin-top:1rem;">

<!-- Safe RL -->
<div class="proj-card" style="border:1px solid #ddd; border-radius:12px; padding:1rem; background:#fff; box-shadow:0 1px 5px rgba(0,0,0,0.05);">
  <img src="/projects1/ehr/hex_ggehr.png" alt="Safe RL" style="width:100%; height:140px; object-fit:contain; margin-bottom:1rem;">
  <h4 style="margin:0 0 0.5rem 0;">🔐 Safe & Trustworthy RL</h4>
  <p>Design agents that ensure safety, robustness, and uncertainty awareness in complex environments.</p>
</div>

<!-- Transfer Learning -->
<div class="proj-card" style="border:1px solid #ddd; border-radius:12px; padding:1rem; background:#fff; box-shadow:0 1px 5px rgba(0,0,0,0.05);">
  <img src="/projects1/icons/transfer_learning.png" alt="Transfer Learning" style="width:100%; height:140px; object-fit:contain; margin-bottom:1rem;">
  <h4 style="margin:0 0 0.5rem 0;">🔄 Transfer & Meta-Adaptation</h4>
  <p>Enable rapid adaptation to unseen domains, environments, or grid conditions using Meta-RL and Sim2Real.</p>
</div>

<!-- Vision-Simulation -->
<div class="proj-card" style="border:1px solid #ddd; border-radius:12px; padding:1rem; background:#fff; box-shadow:0 1px 5px rgba(0,0,0,0.05);">
  <img src="/projects1/icons/vision_sim.png" alt="Vision Sim" style="width:100%; height:140px; object-fit:contain; margin-bottom:1rem;">
  <h4 style="margin:0 0 0.5rem 0;">👁️ Vision-Simulation Integration</h4>
  <p>Bridge perception and control using multi-modal simulation environments and synthetic sensors.</p>
</div>

<!-- LLM-Augmented -->
<div class="proj-card" style="border:1px solid #ddd; border-radius:12px; padding:1rem; background:#fff; box-shadow:0 1px 5px rgba(0,0,0,0.05);">
  <img src="/projects1/icons/llm_control.png" alt="LLM Control" style="width:100%; height:140px; object-fit:contain; margin-bottom:1rem;">
  <h4 style="margin:0 0 0.5rem 0;">🧠 LLM-Augmented Decision Systems</h4>
  <p>Use LLMs for reasoning, planning, and translating natural language into actionable policies.</p>
</div>

</div>


## 🧠 Research Focus Areas {#research-focus}

<!-- Optional styling section-wide (optional if using external CSS) -->
<style>
.proj-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
  gap: 1.5rem;
  margin-top: 1rem;
}
.proj-card {
  border: 1px solid #ddd;
  border-radius: 12px;
  padding: 1.2rem;
  background: #fff;
  box-shadow: 0 1px 6px rgba(0,0,0,0.05);
  display: flex;
  flex-direction: column;
  align-items: center;
}
.proj-card img {
  width: 100%;
  max-height: 140px;
  object-fit: contain;
  margin-bottom: 1rem;
}
</style>

---

### 🔐 Safe & Trustworthy RL

<div class="proj-grid">

<div class="proj-card">
  <img src="/projects1/icons/safe_rl.png" alt="Safe RL">
  <h4>Robust & Stable Learning</h4>
  <p>Develop agents that ensure system safety, robustness, and interpretability under uncertainty.</p>
</div>

<div class="proj-card">
  <img src="/projects1/icons/uncertainty.png" alt="Uncertainty Quantification">
  <h4>Uncertainty-Aware Policies</h4>
  <p>Quantify epistemic and aleatoric uncertainty in high-stakes, partially observable settings.</p>
</div>

</div>

---

### 🔄 Transfer & Meta-Adaptation

<div class="proj-grid">

<div class="proj-card">
  <img src="/projects1/icons/transfer_learning.png" alt="Transfer Learning">
  <h4>Domain Adaptation</h4>
  <p>Enable agents to generalize across grids with different topologies, dynamics, and loads.</p>
</div>

<div class="proj-card">
  <img src="/projects1/icons/meta_rl.png" alt="Meta RL">
  <h4>Meta-RL for Efficiency</h4>
  <p>Leverage meta-reasoning to accelerate learning in low-data, high-variance scenarios.</p>
</div>

</div>

---

### 👁️ Vision-Simulation Integration

<div class="proj-grid">

<div class="proj-card">
  <img src="/projects1/icons/carla.png" alt="Perception Control">
  <h4>Perception-Control Fusion</h4>
  <p>Use CARLA and AirSim to train end-to-end systems in visual RL tasks with sensors.</p>
</div>

<div class="proj-card">
  <img src="/projects1/icons/multimodal.png" alt="Multimodal Fusion">
  <h4>Multi-modal Representations</h4>
  <p>Combine visual, state, and contextual features for better decision-making.</p>
</div>

</div>

---

### 🧠 LLM-Augmented Decision Systems

<div class="proj-grid">

<div class="proj-card">
  <img src="/projects1/icons/llm_state_summary.png" alt="LLM for summarization">
  <h4>LLM-Guided Control</h4>
  <p>Translate natural language into actionable policies for real-world environments.</p>
</div>

<div class="proj-card">
  <img src="/projects1/icons/llm_human_ai.png" alt="Human AI Collaboration">
  <h4>Human-AI Collaboration</h4>
  <p>Facilitate interactive control loops between humans and agents using LLMs.</p>
</div>

</div>
-----------

## 🧠 Research Focus Areas {#research-focus}

<!-- Styling (optional if handled globally) -->
<style>
.proj-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
  gap: 1.5rem;
  margin-top: 0.5rem;
}
.proj-card {
  border: 1px solid #ddd;
  border-radius: 12px;
  padding: 1.2rem;
  background: #fff;
  box-shadow: 0 1px 6px rgba(0,0,0,0.05);
  display: flex;
  flex-direction: column;
  align-items: center;
}
.proj-card img {
  width: 100%;
  max-height: 140px;
  object-fit: contain;
  margin-bottom: 1rem;
}
.group-label {
  font-size: 1.2rem;
  font-weight: 600;
  margin: 2rem 0 0.5rem 0;
  color: #6c2b88;
  display: flex;
  align-items: center;
  gap: 0.5rem;
}
</style>



<!-- Group 1 -->
<div class="group-label">🔐 Safe & Trustworthy RL</div>
<div class="proj-grid">

<div class="proj-card">
  <img src="/projects1/icons/safe_rl.png" alt="Safe RL">
  <h4>Robust & Stable Learning</h4>
  <p>Develop agents that ensure system safety, robustness, and interpretability under uncertainty.</p>
</div>

<div class="proj-card">
  <img src="/projects1/icons/uncertainty.png" alt="Uncertainty Quantification">
  <h4>Uncertainty-Aware Policies</h4>
  <p>Quantify epistemic and aleatoric uncertainty in high-stakes, partially observable settings.</p>
</div>

</div>

<!-- Group 2 -->
<div class="group-label">🔄 Transfer & Meta-Adaptation</div>
<div class="proj-grid">

<div class="proj-card">
  <img src="/projects1/icons/transfer_learning.png" alt="Transfer Learning">
  <h4>Domain Adaptation</h4>
  <p>Enable agents to generalize across grids with different topologies, dynamics, and loads.</p>
</div>

<div class="proj-card">
  <img src="/projects1/icons/meta_rl.png" alt="Meta RL">
  <h4>Meta-RL for Efficiency</h4>
  <p>Leverage meta-reasoning to accelerate learning in low-data, high-variance scenarios.</p>
</div>

</div>

<!-- Group 3 -->
<div class="group-label">👁️ Vision-Simulation Integration</div>
<div class="proj-grid">

<div class="proj-card">
  <img src="/projects1/icons/carla.png" alt="Perception Control">
  <h4>Perception-Control Fusion</h4>
  <p>Use CARLA and AirSim to train end-to-end systems in visual RL tasks with sensors.</p>
</div>

<div class="proj-card">
  <img src="/projects1/icons/multimodal.png" alt="Multimodal Fusion">
  <h4>Multi-modal Representations</h4>
  <p>Combine visual, state, and contextual features for better decision-making.</p>
</div>

</div>

<!-- Group 4 -->
<div class="group-label">🧠 LLM-Augmented Decision Systems</div>
<div class="proj-grid">

<div class="proj-card">
  <img src="/projects1/icons/llm_state_summary.png" alt="LLM for summarization">
  <h4>LLM-Guided Control</h4>
  <p>Translate natural language into actionable policies for real-world environments.</p>
</div>

<div class="proj-card">
  <img src="/projects1/icons/llm_human_ai.png" alt="Human AI Collaboration">
  <h4>Human-AI Collaboration</h4>
  <p>Facilitate interactive control loops between humans and agents using LLMs.</p>
</div>

</div>


## 🔬 Application Domains {#application-domains}

| Domain | Description |
|--------|-------------|
| ⚡ **Smart Energy Systems** | Volt-VAR control, DER coordination, and federated DRL for power grid stability |
| 🚘 **Autonomous Systems** | Safe navigation, adaptive planning, and control in simulation and real-world environments |
| 🛡 **Secure AI for Infrastructure** | Resilience against cyber-attacks and adversarial scenarios in safety-critical systems |

---

<!--
## 🏅 Awards & Recognition {#awards}

- IEEE PES-GM 2024 Travel Grant Recipient  
- Research Excellence Award – Iowa State University  
- Best Poster Award – Grid Edge Technologies 2025  
- NREL Outstanding Internship Recognition  
-->
---

## 📚 Publications {#publications}

::: {.panel-tabset}

### 📝 Journal Papers

1. **Kundan Kumar**, Gelli Ravikumar  
**Physics-based Deep Reinforcement Learning for Grid-Resilient Volt-VAR Control** *(Under Review)*  
*IEEE Transactions on Smart Grid, 2025*  
<span style="display:inline-flex; gap:4px;">
<a class="btn btn-primary btn-sm" href="https://arxiv.org/abs/2202.13541">Paper</a>
<a class="btn btn-success btn-sm" href="#">Code</a>
<a class="btn btn-info btn-sm" href="#">Poster</a>
</span>

---

### 🎤 Conference Papers

1. **Kundan Kumar**, Gelli Ravikumar  
**Transfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids**  
*IEEE PES Grid Edge Technologies, 2025*

2. **Kundan Kumar**, Aditya Akilesh Mantha, Gelli Ravikumar  
**Bayesian Optimization for DRL in Robust Volt-Var Control**  
*IEEE PES General Meeting, 2024*

3. **Kundan Kumar**, Gelli Ravikumar  
**Volt-VAR Control and Attack Resiliency using Deep RL**  
*IEEE ISGT, 2024*

4. JK Francis, C Kumar, J Herrera-Gerena, **Kundan Kumar**, MJ Darr  
**Sensor Data Regression using Deep Learning & Patterns**  
*IEEE ICMLA, 2022*

5. Kin Gwn Lore, Nicholas Sweet, **Kundan Kumar**, et al.  
**Deep Value of Information Estimators for Human-Machine Collaboration**  
*ACM/IEEE ICCPS, 2016*

:::

---

## 🔄 Ongoing Projects {#ongoing-projects}

- 🤖 **Federated DRL for Cyber-Resilient Volt-VAR Optimization**  
  Decentralized, communication-efficient control using LSTM-enhanced PPO agents across distributed DERs.

- ⚡ **One-Shot Policy Transfer with Physics Priors**  
  Train agents on small topologies and adapt to IEEE 123-bus, 8500-node networks in a few iterations.

- 🧠 **LLM-Guided Autonomous Planning for Smart Buildings**  
  Convert user prompts to interpretable control policies using LLMs (OpenAI, Claude) in CityLearn environments.
